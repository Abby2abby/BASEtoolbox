var documenterSearchIndex = {"docs":
[{"location":"Estimation.html#Estimation-of-parameters","page":"Estimation","title":"Estimation of parameters","text":"","category":"section"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"note: Note\nMost of the code of this section is in the submodule Estimation","category":"page"},{"location":"Estimation.html#Settings","page":"Estimation","title":"Settings","text":"","category":"section"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"EstimationSettings","category":"page"},{"location":"Estimation.html#BASEforHANK.Parsing.EstimationSettings","page":"Estimation","title":"BASEforHANK.Parsing.EstimationSettings","text":"EstimationSettings()\n\nCollect settings for the estimation of the model parameters in a struct.\n\nUse package Parameters to provide initial values. Input and output file names are stored in the fields mode_start_file, data_file, save_mode_file and save_posterior_file.\n\n\n\n\n\n","category":"type"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"The estimation settings (globally instantiated as e_set in BASEforHANK.jl) manage the following areas of the estimation:","category":"page"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"the match between data and model: data_file is a path to a .csv-file   that contains quarterly observations of several variables (in columns), named in   observed_vars_input. Missing data is denoted by NaN. If some column-names do not align with the model   variables, data_rename is used. Level variables that should correspond to growth   rates in the data can be selected in growth_rate_select. Measurement errors   will be added for observables in meas_error_input\nestimation of variances: shock_names contain the aggregate shocks in the model,   whose variances are estimated. me_treatment defines how measurement errors   are treated: for :fixed, their variances are fixed by the data-variance, otherwise   they are estimated either with :bounded uniform priors, or :unbounded priors    (see BASEforHANK.Estimation.measurement_error()). For the latter case, the priors are set in   meas_error_distr\nnumerical parameters: the maximum number of iterations to find the mode of the   likelihood (see BASEforHANK.Estimation.mode_finding()) is set in max_iter_mode. ndraws, burnin   and mhscale are parameters for the Random-Walk Metropolis Hastings algorithm (see BASEforHANK.rwmh())\nestimation flags: whether to estimate the model is set in estimate_model. compute_hessian determines whether the Hessian is computed after mode finding or set to an identity matrix (see BASEforHANK.Estimation.mode_finding()). multi_chain_init sets whether multiple chains in the RWMH (see BASEforHANK.Estimation.multi_chain_init() and BASEforHANK.rwmh()) are started from an overdispersed posterior mode. All flags are set to false by default.","category":"page"},{"location":"Estimation.html#Mode-finding","page":"Estimation","title":"Mode finding","text":"","category":"section"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"BASEforHANK.mode_finding","category":"page"},{"location":"Estimation.html#BASEforHANK.Estimation.mode_finding","page":"Estimation","title":"BASEforHANK.Estimation.mode_finding","text":"mode_finding(XSSaggr, A, B, indexes, indexes_aggr, distrSS, compressionIndexes, m_par, n_par, e_set)\n\nGiven definition of observed variables and their transformation (level or growth rate) from e_set, load the data, construct the observation equation, and maximize likeli() (the log-likelihood) using the package Optim.\n\nSave estimation results to e_set.save_mode_file.\n\nReturns\n\npar_final: parameter vector that maximizes the likelihood\nhessian_final: Hessian of the log-likelihood at par_final\nposterior_mode: log-likelihood at par_final\nmeas_error,meas_error_std: returns from measurement_error()\nparnames: names of estimated parameters (including measurement error variances)\nData,Data_missing: data from e_set.data_file; marker for missing data\nH_sel: selector matrix for states/controls that are observed\npriors: priors of parameters (including measurement error variances)\nsmoother_output: output from the Kalman smoother\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"The main computations are the construction of the likelihood of the model parameters and its maximization. We get the model parameters that are to be estimated, together with their priors, from m_par (in addition to measurement error variances, see Settings).","category":"page"},{"location":"Estimation.html#The-likelihood-function","page":"Estimation","title":"The likelihood function","text":"","category":"section"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"The function BASEforHANK.Estimation.likeli() computes the log-likelihood of the model parameters par in the following steps:","category":"page"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"call BASEforHANK.PerturbationSolution.LinearSolution_estim() to derive the linear state-space representation of the model given par.  Differently from BASEforHANK.PerturbationSolution.LinearSolution(), differentiate only the system of aggregate equilibrium  conditions with respect to aggregate variables, i.e. BASEforHANK.PerturbationSolution.Fsys_agg(). This is sufficient,  as the estimated parameters do not enter in the heterogeneous agent part of the equilibrium system [BBL].  Then, update the derivatives A and B of the full model for aggregate variables and conditions,  and compute the observation and state transition equations as in BASEforHANK.PerturbationSolution.LinearSolution()\ndelete rows of the observation equation that correspond to unobserved controls  (the selector matrix H_sel is constructed in BASEforHANK.Estimation.mode_finding()). Then, feed  the linear state-space system, the data, and the variances of the structural and  measurement shocks, into the Kalman filter (see BASEforHANK.Estimation.kalman_filter()), which computes  the log-likelihood","category":"page"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"We find the maximizer of the likelihood function, as well as its Hessian at the maximum, with the package Optim. Note that in order to obtain the Hessian, you need to set e_set.compute_hessian = true.","category":"page"},{"location":"Estimation.html#Called-functions","page":"Estimation","title":"Called functions","text":"","category":"section"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"BASEforHANK.Estimation.likeli\nBASEforHANK.PerturbationSolution.LinearSolution_estim\nBASEforHANK.Estimation.kalman_filter\nBASEforHANK.Estimation.measurement_error","category":"page"},{"location":"Estimation.html#BASEforHANK.Estimation.likeli","page":"Estimation","title":"BASEforHANK.Estimation.likeli","text":"likeli(par, Data, Data_missing, H_sel, priors, meas_error, meas_error_std, sr, lr, m_par, e_set; smoother=false)\n\nCompute the likelihood of Data, given model-parameters par and prior priors (maximize to find MLE of par).\n\nSolve model with LinearSolution_estim(), compute likelihood with kalman_filter() or with kalman_filter_smoother() (if smoother==True).\n\nReturns\n\nif smoother==False:\n\nlog_like,prior_like,post_like,alarm: log-likelihoods (post is the sum of prior and computed likelihood); alarm indicates error when solving model with LinearSolution_estim, sets log-likelihood to -9.e15\n\nif smoother==True:\n\nsmoother_output: returns from kalman_filter_smoother()\n\n\n\n\n\nlikeli(par, sr, lr, er, m_par, e_set; smoother=false)\n\nCompute the likelihood of er.Data, given model-parameters par and prior er.priors (maximize to find MLE of par).\n\nSolve model with LinearSolution_estim(), compute likelihood with kalman_filter() or with kalman_filter_smoother() (if smoother==True).\n\nReturns\n\nif smoother==False:\n\nlog_like,prior_like,post_like,alarm: log-likelihoods (post is the sum of prior and computed likelihood); alarm indicates error when solving model with LinearSolution_estim, sets log-likelihood to -9.e15\n\nif smoother==True:\n\nsmoother_output: returns from kalman_filter_smoother()\nState2Control,LOM: state-to-control and state transition matrizzes\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html#BASEforHANK.PerturbationSolution.LinearSolution_estim","page":"Estimation","title":"BASEforHANK.PerturbationSolution.LinearSolution_estim","text":"LinearSolution_estim(sr, m_par, A, B,;estim)\n\nCalculate the linearized solution to the non-linear difference equations defined by function Fsys, while only differentiating with respect to the aggregate part of the model, Fsys_agg().\n\nThe partials of the Jacobian belonging to the heterogeneous agent part of the model are taken from the full-model derivatives provided as arguments, A and B (computed by LinearSolution()).\n\nArguments\n\nsr: steady-state structure (variable values, indexes, numerical parameters, ...)\nA,B: derivative of Fsys() with respect to arguments X [B] and   XPrime [A]\nm_par: model parameters\n\nReturns\n\nas in LinearSolution()\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html#BASEforHANK.Estimation.kalman_filter","page":"Estimation","title":"BASEforHANK.Estimation.kalman_filter","text":"kalman_filter(H,LOM,Data,D_miss,SCov,MCov,e_set)\n\nCompute likelihood of Data, applying the Kalman filter to the state-space represenation (H,LOM) of the model.\n\nArguments\n\nH::Array{Float64,2}: observation equation\nLOM::Array{Float64,2}: law of motion for states\nData::Array{Union{Missing,Float64},2},D_miss::BitArray{2}: data (time times variable); marker for missing data\nSCov::Array{Float64,2}: covariance of structural shocks\nMCov::Array{Float64,2}: covariance of measurement error\n\nReturns\n\nlog-likelihood\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html#BASEforHANK.Estimation.measurement_error","page":"Estimation","title":"BASEforHANK.Estimation.measurement_error","text":"measurement_error(Data,observed_vars,e_set)\n\nBuild measurement error.\n\nArguments\n\nData: matrix of observables [nobs * nvar]\nobserved_vars: vector of observed variable names [nvar * 1]\ne_set::EstimationSettings\n\nReturns\n\nmeas_error: ordered dictionary of measurement errors linked to observables\nmeas_error_prior: corresponding priors for measurement errors\nmeas_error_std: standard deviations of observables with measurement error\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html#Bayesian-estimation","page":"Estimation","title":"Bayesian estimation","text":"","category":"section"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"sample_posterior","category":"page"},{"location":"Estimation.html#BASEforHANK.sample_posterior","page":"Estimation","title":"BASEforHANK.sample_posterior","text":"mcmc_estimation(mr,er;file=e_set.save_posterior_file)\n\nSample posterior of parameter vector with rwmh(), take sample mean as parameter estimate, and save all results in file.\n\nArguments\n\nsr::SteadyResults\nmr::LinearResults\ner::EstimResults\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"We use a Monte Carlo Markov Chain method, specifically the Random-Walk Metropolis Hastings (BASEforHANK.Estimation.rwmh()) algorithm, to sample from the posterior probability distribution of the parameter vector. The acceptance rate of the algorithm can be adjusted via setting EstimationSettings.mhscale. To obtain the posterior likelihood of each draw, we call BASEforHANK.Estimation.likeli(), which evaluates the priors at par (BASEforHANK.Estimation.prioreval()) and returns the log-posterior as a sum of the log-prior and the log-likelihood.","category":"page"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"Given the draws from the posterior, we can analyze the probabilities of the parameters using the package MCMCChains. We take the average over the draws as our Bayesian estimate of the parameter vector, par_final. To obtain an estimate of the underlying state over the data sample period, we call BASEforHANK.Estimation.likeli() with par_final and keyword smoother=true (this calls the Kalman smoother BASEforHANK.Estimation.kalman_filter_smoother()). The result is stored in smoother_output, and saved with the other results in e_set.save_posterior_file.","category":"page"},{"location":"Estimation.html#Called-functions-2","page":"Estimation","title":"Called functions","text":"","category":"section"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"BASEforHANK.Estimation.rwmh\nBASEforHANK.Estimation.multi_chain_init\nBASEforHANK.Estimation.prioreval\nBASEforHANK.Estimation.kalman_filter_smoother","category":"page"},{"location":"Estimation.html#BASEforHANK.Estimation.rwmh","page":"Estimation","title":"BASEforHANK.Estimation.rwmh","text":"rwmh(xhat, Σ, sr, lr, er, m_par, e_set)\n\nSample the posterior of the parameter vector using the Random-Walk Metropolis Hastings algorithm.\n\nReturns\n\ndraws::Array{Float64,2}: e_set.ndraws + e_set.burnin sampled parameter vectors (row vectors)\nposterior: vector of posteriors for the respective draws\naccept_rate: acceptance rate\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html#BASEforHANK.Estimation.multi_chain_init","page":"Estimation","title":"BASEforHANK.Estimation.multi_chain_init","text":"multi_chain_init(xhat, Σ, sr, lr, er, m_par, e_set)\n\nDraw overdispersed initial values for multi-chain RWMH.\n\nReturns\n\ninit_draw: overdispersed starting value for chain\ninit_draw: Bool variable indicating whether search was succesful\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html#BASEforHANK.Estimation.prioreval","page":"Estimation","title":"BASEforHANK.Estimation.prioreval","text":"prioreval(par,priors)\n\nEvaluate prior PDF at the parameters given in par.\n\nArguments\n\npar: vector of parameters [npar*1]\npriors: vector of prior distributions [npar*1]\n\nReturns\n\nlog_priorval: log prior density [scalar]\nalarm: indicator that is 1 if there is a violation of the prior bounds [scalar]\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html#BASEforHANK.Estimation.kalman_filter_smoother","page":"Estimation","title":"BASEforHANK.Estimation.kalman_filter_smoother","text":"kalman_filter_smoother(H, LOM, Data, D_nomiss, SCov, MCov, e_set)\n\nCompute likelihood and estimate of underlying states given the full observed Data by applying the Kalman smoother to the state-space representation (H,LOM) of the model.\n\nArguments\n\nH::Array{Float64,2}: observation equation\nLOM::Array{Float64,2}: law of motion for states\nData::Array{Union{Missing,Float64},2},D_nomiss::BitArray{2}: data (time times variable); marker for existent data\nSCov::Array{Float64,2}: covariance of structural shocks\nMCov::Array{Float64,2}: covariance of measurement error\n\nReturns\n\nlog_lik: log-likelihood\nxhat_tgt,xhat_tgT: estimate of underlying states from forward iteration [xhat_tgt] and   backward iteration [xhat_tgT]\nSigma_tgt,Sigma_tgT: estimate of covariance matrices from forward iteration [Sigma_tgt]   and backward iteration [Sigma_tgT]\ns,m: smoothed structural shocks [s] and measurement errors [m]\n\n\n\n\n\n","category":"function"},{"location":"Estimation.html","page":"Estimation","title":"Estimation","text":"[BBL]: For details, see the paper Shocks, Frictions, and Inequality in US Business Cycles, American Economic Review, forthcoming.","category":"page"},{"location":"Parsing.html#Parsing","page":"Parser","title":"Parsing","text":"","category":"section"},{"location":"Parsing.html","page":"Parser","title":"Parser","text":"The Parsing submodule provides macros used for automatic code generation, structs, indexes, etc. These map, e.g., deviations from steady state of aggregate variables to equations lines in the non-linear difference equation that describe the economy. ","category":"page"},{"location":"Parsing.html#Collect-variables:-macros","page":"Parser","title":"Collect variables: macros","text":"","category":"section"},{"location":"Parsing.html","page":"Parser","title":"Parser","text":"BASEforHANK.Parsing.@writeXSS\nBASEforHANK.Parsing.@make_fn\nBASEforHANK.Parsing.@make_fnaggr\nBASEforHANK.Parsing.@make_struct\nBASEforHANK.Parsing.@make_struct_aggr\nBASEforHANK.Parsing.@generate_equations","category":"page"},{"location":"Parsing.html#BASEforHANK.Parsing.@writeXSS","page":"Parser","title":"BASEforHANK.Parsing.@writeXSS","text":"@writeXSS()\n\nWrite all single steady state variables into vectors XSS / XSSaggr.\n\nRequires\n\n(module) globals state_names, control_names, aggr_names\n\n\n\n\n\n","category":"macro"},{"location":"Parsing.html#BASEforHANK.Parsing.@make_fn","page":"Parser","title":"BASEforHANK.Parsing.@make_fn","text":"@make_fn(fn_name)\n\nCreate function fn_name that returns an instance of struct IndexStruct (created by @make_struct), mapping states and controls to indexes inferred from numerical parameters and compression indexes.\n\nRequires\n\n(module) global state_names, control_names\n\n\n\n\n\n","category":"macro"},{"location":"Parsing.html#BASEforHANK.Parsing.@make_fnaggr","page":"Parser","title":"BASEforHANK.Parsing.@make_fnaggr","text":"@make_fnaggr(fn_name)\n\nCreate function fn_name that returns an instance of struct IndexStructAggr (created by @make_struct_aggr), mapping aggregate states and controls to values 1 to length(aggr_names) (both steady state and deviation from it).\n\nRequires\n\n(module) global aggr_names\n\n\n\n\n\n","category":"macro"},{"location":"Parsing.html#BASEforHANK.Parsing.@make_struct","page":"Parser","title":"BASEforHANK.Parsing.@make_struct","text":"@make_struct(struct_name)\n\nMake struct struct_name with two fields for every variable name in s_names (state variables) and c_names (control variables), together with fields for distribution-states and marginal value function-controls.\n\nRequires\n\n(module) globals state_names, control_names\n\n\n\n\n\n","category":"macro"},{"location":"Parsing.html#BASEforHANK.Parsing.@make_struct_aggr","page":"Parser","title":"BASEforHANK.Parsing.@make_struct_aggr","text":"@make_struct_aggr(struct_name)\n\nMake struct struct_name with two fields for every variable name in aggr_names (for steady state value and for deviation from it).\n\nRequires\n\n(module) global aggr_names\n\n\n\n\n\n","category":"macro"},{"location":"Parsing.html#BASEforHANK.Parsing.@generate_equations","page":"Parser","title":"BASEforHANK.Parsing.@generate_equations","text":"@generate_equations()\n\nWrite out the expansions around steady state for all variables in aggr_names, i.e. generate code that reads aggregate states/controls from steady state deviations.\n\nEquations take the form of (with variable r as example):\n\nr       = exp.(XSS[indexes.rSS] .+ X[indexes.r])\nrPrime  = exp.(XSS[indexes.rSS] .+ XPrime[indexes.r])\n\nRequires\n\n(module) global aggr_names\n\n\n\n\n\n","category":"macro"},{"location":"PostEstimation.html#Post-Estimation-Commands","page":"Post estimation","title":"Post Estimation Commands","text":"","category":"section"},{"location":"PostEstimation.html","page":"Post estimation","title":"Post estimation","text":"The PostEstimation submodule provides a set of functions for post-estimation analysis. These functions are designed to work with the output of the model estimation process and provide further insights into the model's behavior. The functions provide plots of impulse responses, variance decompositions and historical decompositions, as well as tables in form of dataframes, where appropriate.  ","category":"page"},{"location":"PostEstimation.html#Usage","page":"Post estimation","title":"Usage","text":"","category":"section"},{"location":"PostEstimation.html","page":"Post estimation","title":"Post estimation","text":"You can use these functions by importing the PostEstimation module. Here's an example:","category":"page"},{"location":"PostEstimation.html","page":"Post estimation","title":"Post estimation","text":"using .BASEforHANK.PostEstimation\n\n# Now you can call the functions\ncompute_hist_decomp(...)","category":"page"},{"location":"PostEstimation.html#Functions","page":"Post estimation","title":"Functions","text":"","category":"section"},{"location":"PostEstimation.html#Impulse-Responses","page":"Post estimation","title":"Impulse Responses","text":"","category":"section"},{"location":"PostEstimation.html","page":"Post estimation","title":"Post estimation","text":"compute_irfs_vardecomp\nplot_irfs","category":"page"},{"location":"PostEstimation.html#BASEforHANK.PostEstimation.compute_irfs_vardecomp","page":"Post estimation","title":"BASEforHANK.PostEstimation.compute_irfs_vardecomp","text":"compute_irfs_vardecomp(models, select_variables)\n\nThis function calculates a variance decomposition of the given models for selected variables.  It returns four outputs: the impulse responses, the fixed horizon decompositions,  the list of shocks that drive the model, and finally the variance decomposition based on the  method proposed by Uhlig (2001).\n\nArguments\n\nmodels: The models for which the variance decomposition will be calculated. This should be a collection of models.\nselect_variables: The variables selected for the variance decomposition. This should be a collection of variable names.\n\nReturns\n\nIRFs: The impulse responses of the models.\nVDs: The fixed horizon decompositions of the models.\nSHOCKs: The shocks applied to the models.\nVD_bc_s: The variance decomposition based on the method proposed by Harald Uhlig (2001).\n\nExamples\n\nIRFs, VDs, SHOCKs, VD_bc_s = compute_irfs_vardecomp(models, select_variables)\n\n\n\n\n\n","category":"function"},{"location":"PostEstimation.html#BASEforHANK.PostEstimation.plot_irfs","page":"Post estimation","title":"BASEforHANK.PostEstimation.plot_irfs","text":"plot_irfs(IRFs, SHOCKs, select_variables, nice_var_names, nice_s_names, horizon, model_names, n_plotcol; savepdf = false, disp_switch = true, suffix = \"\")\n\nThis function is designed to plot impulse response functions (IRFs).  It takes as input the impulse responses, shocks, selected variables, nice variable names, nice shock names, horizon, model names, and number of plot columns, and generates a plot.\n\nArguments\n\nIRFs: The impulse responses to be plotted. This should be a collection of impulse responses (an Array).\nSHOCKs: The symbols of the shocks applied to the models.\nselect_variables: The variables to be displayed in the plot. This should be a collection of variable names, a collection of strings.\nnice_var_names: The readable names of the variables to be displayed in the plot. This should be a collection of strings.\nnice_s_names: The readable names of the shocks to be displayed in the plot. This should be a collection of strings.\nhorizon: The horizon over which to plot the impulse response functions.\nmodel_names: The names of the models. This should be an array of strings.\nn_plotcol: The number of plot columns.\n\nOptional Arguments\n\nsavepdf: A boolean indicating whether to save the plot as a PDF. Default is false.\ndisp_switch: A boolean indicating whether to display the switch. Default is true.\nsuffix: A string to be appended to the end of the file name when saving the plot as a PDF.\n\nReturns\n\nThis function returns a vector of plots.\n\nExamples\n\nplot_irfs(IRFs, SHOCKs, select_variables, nice_var_names, nice_s_names, horizon, model_names, n_plotcol)\n\n\n\n\n\n","category":"function"},{"location":"PostEstimation.html#Variance-Decomposition","page":"Post estimation","title":"Variance Decomposition","text":"","category":"section"},{"location":"PostEstimation.html","page":"Post estimation","title":"Post estimation","text":"compute_bcfreq_vardecomp\nplot_vardecomp\ncompute_vardecomp_bounds","category":"page"},{"location":"PostEstimation.html#BASEforHANK.PostEstimation.compute_bcfreq_vardecomp","page":"Post estimation","title":"BASEforHANK.PostEstimation.compute_bcfreq_vardecomp","text":"compute_bcfreq_vardecomp(sr, lr, e_set, m_par; passband = (6, 32), ngrid = 512)\n\nThis function is designed to produce a variance decomposition at business cycle frequencies.  It produces a variance decomposition of the linearized solution. It returns the variance decomposition at business  cycle frequencies based on Uhlig (2001) and the unconditional variance.\n\nArguments\n\nsr: Steady state.\nlr: Linearized Solution.\ne_set: Estimation parameters.\nm_par: Model parameters.\npassband: A tuple specifying the horizons associated with the business cycle. Default is (6, 32).\nngrid: The number of grid points for the computation of the band pass filter. Default is 512.\n\nReturns\n\nvar_decomp: This function returns a variance decomposition.\n\nExamples\n\nvar_decomp = compute_bcfreq_vardecomp(sr, lr, e_set, m_par)\n\n\n\n\n\n","category":"function"},{"location":"PostEstimation.html#BASEforHANK.PostEstimation.plot_vardecomp","page":"Post estimation","title":"BASEforHANK.PostEstimation.plot_vardecomp","text":"plot_vardecomp(VDs, VD_bc_s, select_vd_horizons, model_names, SHOCKs, select_variables; savepdf = false, suffix = \"\", legend_switch = true, disp_switch = true)\n\nThis function is designed to plot variance decompositions. It takes as input the variance decompositions.  These are the variance decomposition based on the method proposed by Harald Uhlig (2001) as well as variance  decomposition at fixed horizons. It further expects as inputs model names, shocks as symbols, and the variables selected to be displayed. It generates a plot.\n\nArguments\n\nVDs: The variance decompositions to be plotted. This should be a collection of variance decompositions at fixed horizons.\nVD_bc_s: The variance decomposition based on the method proposed by Harald Uhlig (2001).\nselect_vd_horizons: The horizons of the variance decompositions to be displayed in the plot. This should be a collection of integers.\nmodel_names: The names of the models for which the varaiance decompositions are provided. This should be an array of strings.\nSHOCKs: The symbols of the shocks applied to the models.\nselect_variables: The variables to be displayed in the plot. This should be a collection of variable names.\n\nOptional Arguments\n\nsavepdf: A boolean indicating whether to save the plot as a PDF. Default is false.\nsuffix: A string to be appended to the end of the file name when saving the plot as a PDF.\nlegend_switch: A boolean indicating whether to display the legend. Default is true.\ndisp_switch: A boolean indicating whether to display the switch. Default is true.\n\nReturns\n\nThis function returns the plotted variance decompositions as data frames.\n\nExamples\n\nplot_vardecomp(VDs, VD_bc_s, select_vd_horizons, model_names, SHOCKs, select_variables)\n\n\n\n\n\n","category":"function"},{"location":"PostEstimation.html#BASEforHANK.PostEstimation.compute_vardecomp_bounds","page":"Post estimation","title":"BASEforHANK.PostEstimation.compute_vardecomp_bounds","text":"compute_vardecomp_bounds(models, select_variables, model_names; n_replic = 1000, percentile_bounds = (0.05, 0.95))\n\nThis function uses a Monte Carlo method to determine the credible bounds for the variance decomposition of the given  models for selected variables, based on the method proposed by Uhlig (2001). \n\nArguments\n\nmodels: The models for which the variance decomposition will be calculated. This should be a collection of models .\nselect_variables: The variables selected for the variance decomposition. This should be a collection of variable names.\nmodel_names: The names of the models. This should be a collection of strings.\nn_replic: The number of replications for the Monte Carlo method. Default is 1000.\npercentile_bounds: A tuple specifying the lower and upper percentile bounds for the credible interval. Default is (0.05, 0.95).\n\nReturns\n\nbounds: This function returns the credible bounds for the variance decomposition of the models.\n\nExamples\n\nbounds = compute_vardecomp_bounds(models, select_variables, model_names)\n\n\n\n\n\n","category":"function"},{"location":"PostEstimation.html#Historical-Decomposition","page":"Post estimation","title":"Historical Decomposition","text":"","category":"section"},{"location":"PostEstimation.html","page":"Post estimation","title":"Post estimation","text":"compute_hist_decomp","category":"page"},{"location":"PostEstimation.html#BASEforHANK.PostEstimation.compute_hist_decomp","page":"Post estimation","title":"BASEforHANK.PostEstimation.compute_hist_decomp","text":"compute_hist_decomp(sr, lr, e_set, m_par, smoother_output, select_variables, timeline; savepdf = false, prefix = \"\")\n\nThis function is designed to compute historical decompositions.  It takes as input the steady state structures (sr), linearized solutions (lr), the estimation settings (eset),  model parameters (mpar), smoother output, selected variables, and timeline.\n\nArguments\n\nsr: The steady state of the model.\nlr: The linearized solution of the model.\ne_set: The estimation settings.\nm_par: The parameters of the model.\nsmoother_output: The output of the smoother.\nselect_variables: The variables to be included in the historical decomposition. This should be a collection of variable names.\ntimeline: The timeline for the historical decomposition.\n\nOptional Arguments\n\nsavepdf: A boolean indicating whether to save the output as a PDF. Default is false.\nprefix: A string to be prepended to the file name when saving the output as a PDF.\n\nReturns\n\nShockContribution: the series of shock contribution for each variable and each shock. \nHistDecDF: the historical decomposition as a data frame, \np: and the plot as a vector of plots.\n\nExamples\n\ncompute_hist_decomp(sr, lr, e_set, m_par, smoother_output, select_variables, timeline)\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html#Computation-of-the-steady-state-and-dimensionality-reduction","page":"Steady state","title":"Computation of the steady state and dimensionality reduction","text":"","category":"section"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"note: Note\nMost of the code of this section is in the submodule SteadyState, except for  prepare_linearization() which is generated by the preprocessor and can be found in  Preprocessor/generated_fcns/. The preprocessor uses a  template stored in Preprocessor/template_fcns/.","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"The model features uninsured income shocks y (by assumption, all workers supply the same efficiency units of labor [BBL], so idiosyncratic productivity shocks translate to income shocks) and two assets, liquid assets (bonds) m and illiquid assets (capital) k. Entrepreneurs (last income-state) receive no labor income, but firm profits, while workers additionally receive labor union profits.                                                                                                ","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"The steady state equilibrium contains marginal value functions V_m and V_k on a three-dimensional grid (m times k times y) and the ergodic joint distribution over these idiosyncratic states. We do dimensionality reduction [BL] by applying the Discrete Cosine Transformation to the marginal value functions and approximating the joint distribution with a copula and state-dependent marginals.","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"The main functions are call_find_steadystate() and call_prepare_linearization():","category":"page"},{"location":"SteadyState.html#compute_steadystate","page":"Steady state","title":"compute_steadystate","text":"","category":"section"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"compute_steadystate","category":"page"},{"location":"SteadyState.html#BASEforHANK.compute_steadystate","page":"Steady state","title":"BASEforHANK.compute_steadystate","text":"compute_steadystate()\n\nCompute steady state including the preparation for linearization\n\nReturns\n\nstruct SteadyResults, containing returns of prepare_linearization()\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"Combines steady state computation and preparation of linearization in one function call. It has the same returns as call_prepare_linearization. ","category":"page"},{"location":"SteadyState.html#call_find_steadystate","page":"Steady state","title":"call_find_steadystate","text":"","category":"section"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"call_find_steadystate\nBASEforHANK.SteadyState.find_steadystate","category":"page"},{"location":"SteadyState.html#BASEforHANK.call_find_steadystate","page":"Steady state","title":"BASEforHANK.call_find_steadystate","text":"call_findsteadystate()\n\nComputes the steady state and fills the SteadyStateStruct struct – without further steps of preparing the linearization.\n\nReturns\n\nstruct SteadyStateStruct, containing returns of find_steadystate()\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html#BASEforHANK.SteadyState.find_steadystate","page":"Steady state","title":"BASEforHANK.SteadyState.find_steadystate","text":"find_steadystate(m_par)\n\nFind the stationary equilibrium capital stock.\n\nReturns\n\nKSS: steady-state capital stock\nVmSS, VkSS: marginal value functions\ndistrSS::Array{Float64,3}: steady-state distribution of idiosyncratic states, computed by Ksupply()\nn_par::NumericalParameters,m_par::ModelParameters\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"The function takes the parameter struct ModelParameters as input m_par (see Parameters).","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"To find the stationary equilibrium, we proceed in roughly the following steps:","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"instantiate the parameter struct NumericalParameters as n_par (see Parameters). Within the struct, we set the number of income states [ny] and use the BASEforHANK.Tools.Tauchen()  method to obtain a grid and a transition matrix of income, given the autocorrelation of the income process [m_par.ρ_h].  Then, include entrepreneurial state.\nfind equilibrium capital stock (by finding a root of BASEforHANK.SteadyState.Kdiff()), where  the supply of capital by households is calculated in BASEforHANK.SteadyState.Ksupply(),  which uses the Endogenous Grid Method (see BASEforHANK.SteadyState.EGM_policyupdate())  to iteratively obtain optimal policies and marginal value functions. Root finding is performed using Brent's method where the customized algorithm generates initial guesses for value functions and distributions based on previous iterations in the root finding. The supply of capital by households is computed based on the eigenvector associated with the unit eigenvalue of the transition matrix that comes out of the households' policies.","category":"page"},{"location":"SteadyState.html#call_prepare_linearization","page":"Steady state","title":"call_prepare_linearization","text":"","category":"section"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"call_prepare_linearization\nBASEforHANK.PerturbationSolution.prepare_linearization","category":"page"},{"location":"SteadyState.html#BASEforHANK.call_prepare_linearization","page":"Steady state","title":"BASEforHANK.call_prepare_linearization","text":"call_prepare_linearization()\n\nRuns the prepare linearization and fills the SteadyResults struct, sr.\n\nReturns\n\nstruct SteadyResults, containing returns of prepare_linearization()\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html#BASEforHANK.PerturbationSolution.prepare_linearization","page":"Steady state","title":"BASEforHANK.PerturbationSolution.prepare_linearization","text":"prepare_linearization(KSS, VmSS, VkSS, distrSS, n_par, m_par)\n\nCompute a number of equilibrium objects needed for linearization.\n\nArguments\n\nKSS: steady-state capital stock\nVmSS, VkSS: marginal value functions\ndistrSS::Array{Float64,3}: steady-state distribution of idiosyncratic states, computed by Ksupply()\nn_par::NumericalParameters,m_par::ModelParameters\n\nReturns\n\nXSS::Array{Float64,1}, XSSaggr::Array{Float64,1}: steady state vectors produced by @writeXSS()\nindexes, indexes_aggr: structs for accessing XSS,XSSaggr by variable names, produced by @make_fn(),       @make_fnaggr()\ncompressionIndexes::Array{Array{Int,1},1}: indexes for compressed marginal value functions (V_m and V_k)\nCopula(x,y,z): function that maps marginals x,y,z to approximated joint distribution, produced by       myinterpolate3()\nn_par::NumericalParameters,m_par::ModelParameters\nCDFSS, CDF_m, CDF_k, CDF_y: cumulative distribution functions (joint and marginals)\ndistrSS::Array{Float64,3}: steady state distribution of idiosyncratic states, computed by Ksupply()\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"We first calculate other equilibrium quantities and produce distributional summary statistics (BASEforHANK.Tools.distrSummaries()). Next, we reduce the dimensionality:","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"Find the sparse representation of fluctuations of V_m and V_k around the steady state. For this purpose,  calculate the derivatives of V_m and V_k with respect to all prices  that enter the household problem. Then transform these derivatives using the   Discrete Cosine Transformation (Julia-package FFTW) into polynomial coefficients.   Calculate the average absolute value of those coefficients and retain those that explain a large   share of the variance of coefficients (up to 100*(1-n_par.reduc_marginal_value) percent).   Add, in the same way, polynomial coefficients that explain  V_m and V_k themselves.   The quality of the latter approximation is controlled by n_par.reduc_value.   The corresponding indices are saved in compressionIndexes. This whole step   is being done in first_stage_reduction().\nPrepare a node mesh on which the time-varying linear interpolant of the copula   is defined. The grid in each m, k, and y dimension is selected    such that each resulting bin holds approximately the same share of the   respective aggregate variable. ","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"Lastly, we collect the steady-state values of all model variables in the  vector XSS (see BASEforHANK.Parsing.@writeXSS). The state variables consist of the marginal distributions over m, k and y and the aggregate state variables (collected in state_names). The control variables consist of the steady state marginal value functions (over the full grid) and the aggregate control variables (collected in control_names; these vectors are defined in the main script BASEforHANK.jl).","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"While the steady-state marginal value functions have full dimensionality, in the vectors that collect deviations from steady state (in BASEforHANK.PerturbationSolution.Fsys(), those are X and XPrime) only the coefficients of the most important Chebyshev polynomials are saved. Additionally, the deviations of the marginal distributions are saved with one entry short of the grid size, since the marginals are restricted to sum up to 1. We manage this by creating the struct indexes (using BASEforHANK.Parsing.@make_fn), that has two fields for each variable: steady state value and deviation.","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"We also construct the vector XSSaggr and the struct indexes_aggr, which are similar to the above but only store (and manage) aggregate variables. This is useful for differentiating only with respect to aggregate variables in the estimation part (see BASEforHANK.PerturbationSolution.LinearSolution_estim()).","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"warning: Warning\nIf you change the household decision model and hence need to customize the steady state solution,  you will need to adjust the template Preprocessor/template_fcns/prepare_linearization.jl and not Preprocessor/generated_fcns/prepare_linearization_generated.jl which will be overwritten by the model parser based on Preprocessor/template_fcns/prepare_linearization.jl. Note that the \"definition\" of the function (right click in VSCode) in the module is the generated one.","category":"page"},{"location":"SteadyState.html#Parameters","page":"Steady state","title":"Parameters","text":"","category":"section"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"The model parameters for the steady state have to be calibrated. We set them in the struct ModelParameters. It also contains all other parameters that are estimated, including the stochastic process-parameters for the aggregate shocks.","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"ModelParameters","category":"page"},{"location":"SteadyState.html#BASEforHANK.Parsing.ModelParameters","page":"Steady state","title":"BASEforHANK.Parsing.ModelParameters","text":"ModelParameters()\n\nCollect all model parameters with calibrated values / priors for estimation in a struct.\n\nUses packages Parameters, FieldMetadata, Flatten. Boolean value denotes whether parameter is estimated.\n\nExample\n\njulia> m_par = ModelParameters();\njulia> # Obtain vector of prior distributions of parameters that are estimated.\njulia> priors = collect(metaflatten(m_par, prior))\n\n\n\n\n\n","category":"type"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"The numerical parameters contain the grid (and the meshes) on which the stationary equilibrium is solved, discretization results of call_find_steadystate()  like the transition matrix of income and the joint distribution, and other parameters that determine the numerical approximation or solution technique, like reduc or sol_algo.","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"NumericalParameters","category":"page"},{"location":"SteadyState.html#BASEforHANK.Parsing.NumericalParameters","page":"Steady state","title":"BASEforHANK.Parsing.NumericalParameters","text":"NumericalParameters()\n\nCollect parameters for the numerical solution of the model in a struct.\n\nUse package Parameters to provide initial values.\n\nExample\n\njulia> n_par = NumericalParameters(mmin = -6.6, mmax = 1000)\n\n\n\n\n\n","category":"type"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"In particular, ny, nk, and nm control the resolution for the income, illiquid asset, and liquid asset grid. The resolution of the copula used in the linearization does not need to coincide with that grid and is controled by ny_copula, nk_copula, and nm_copula, respectively. Note, however, that the copula resolution should not exceed the actual grid size.","category":"page"},{"location":"SteadyState.html#Find-stationary-equilibrium:-functions","page":"Steady state","title":"Find stationary equilibrium: functions","text":"","category":"section"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"BASEforHANK.SteadyState.Kdiff\nBASEforHANK.SteadyState.Ksupply\nBASEforHANK.SteadyState.EGM_policyupdate","category":"page"},{"location":"SteadyState.html#BASEforHANK.SteadyState.Kdiff","page":"Steady state","title":"BASEforHANK.SteadyState.Kdiff","text":"Kdiff(K_guess, \nn_par, \nm_par, \ninitial = true, \nVm_guess = zeros(1, 1, 1), \nVk_guess = zeros(1, 1, 1), \ndistr_guess = zeros(1, 1, 1))\n\nCalculate the difference between the capital stock that is assumed and the capital stock that prevails under that guessed capital stock's implied prices when households face idiosyncratic income risk (Aiyagari model).\n\nRequires global functions from the IncomesETC module incomes() and Ksupply().\n\nArguments\n\nK_guess::Float64: capital stock guess\nn_par::NumericalParameters, \nm_par::ModelParameters\n5 optional arguments:\ninitial::Bool = true: whether to use initial guess for marginal values\nVm_guess::AbstractArray = zeros(1, 1, 1): initial guess for marginal value of liquid assets\nVk_guess::AbstractArray = zeros(1, 1, 1): initial guess for marginal value of illiquid assets\ndistr_guess::AbstractArray = zeros(1, 1, 1): initial guess for stationary distribution\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html#BASEforHANK.SteadyState.Ksupply","page":"Steady state","title":"BASEforHANK.SteadyState.Ksupply","text":"Ksupply(RB_guess,R_guess,w_guess,profit_guess,n_par,m_par)\n\nCalculate the aggregate savings when households face idiosyncratic income risk.\n\nIdiosyncratic state is tuple (mky), where m: liquid assets, k: illiquid assets, y: labor income\n\nArguments\n\nR_guess: real interest rate illiquid assets\nRB_guess: nominal rate on liquid assets\nw_guess: wages\nprofit_guess: profits\nn_par::NumericalParameters\nm_par::ModelParameters\n\nReturns\n\nK,B: aggregate saving in illiquid (K) and liquid (B) assets\nTransitionMat,TransitionMat_a,TransitionMat_n: sparse transition matrices   (average, with [a] or without [n] adjustment of illiquid asset)\ndistr: ergodic steady state of TransitionMat\nc_a_star,m_a_star,k_a_star,c_n_star,m_n_star: optimal policies for   consumption [c], liquid [m] and illiquid [k] asset, with [a] or   without [n] adjustment of illiquid asset\nV_m,V_k: marginal value functions\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html#BASEforHANK.SteadyState.EGM_policyupdate","page":"Steady state","title":"BASEforHANK.SteadyState.EGM_policyupdate","text":"EGM_policyupdate(EVm,EVk,Qminus,πminus,RBminus,Tshock,inc,n_par,m_par,warnme)\n\nFind optimal policies, given marginal continuation values EVm, EVk, today's prices [Qminus, πminus,RBminus], and income [inc], using the Endogenous Grid Method.\n\nOptimal policies are defined on the fixed grid, but optimal asset choices (m and k) are off-grid values.\n\nReturns\n\nc_a_star,m_a_star,k_a_star,c_n_star,m_n_star: optimal (on-grid) policies for   consumption [c], liquid [m] and illiquid [k] asset, with [a] or   without [n] adjustment of illiquid asset\n\n\n\n\n\n","category":"function"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"[BBL]: For details, see the paper Shocks, Frictions, and Inequality in US Business Cycles, American Economic Review, forthcoming.","category":"page"},{"location":"SteadyState.html","page":"Steady state","title":"Steady state","text":"[BL]: For details, see the paper Solving heterogeneous agent models in discrete time with many idiosyncratic states by perturbation methods, Quantitative Economics, Vol.11(4), November 2020, p. 1253-1288.","category":"page"},{"location":"PerturbationSolution.html#Linear-perturbation-around-steady-state","page":"Perturbation solution","title":"Linear perturbation around steady state","text":"","category":"section"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"note: Note\nThe main functions of this section are in the Submodule PerturbationSolution.","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"The model is linearized with respect to aggregate variables. For this, we write the equilibrium conditions in the form of F(XX)=0, where X and X are (expected) deviations from steady state in two successive periods. Applying the total differential yields A*X = - B*X, where A,B are the first derivatives of F with respect to X,X. In the standard setting, we use the generalized Schur decomposition [Klein] to transform this equation into a linearized observation equation d = gx*k and a linearized state transition equation k = hx*k, where k is a vector of the state variables and d is a vector of the control variables, X = beginbmatrix k  d endbmatrix.","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"In our code, F is implemented as BASEforHANK.PerturbationSolution.Fsys(), while differentiating and solving for gx and hx is done in BASEforHANK.PerturbationSolution.LinearSolution(), called by linearize_full_model() returns the results as a struct LinearResults:","category":"page"},{"location":"PerturbationSolution.html#linearize_full_model()","page":"Perturbation solution","title":"linearize_full_model()","text":"","category":"section"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"linearize_full_model\nBASEforHANK.LinearSolution","category":"page"},{"location":"PerturbationSolution.html#BASEforHANK.linearize_full_model","page":"Perturbation solution","title":"BASEforHANK.linearize_full_model","text":"linearize_full_model()\n\nLinearize the full model (i.e. including idiosyncratic states and controls) around the steady state, and solves using LinearSolution().\n\nReturns\n\nstruct LinearResults, containing\n\nA::Array{Float64,2},B::Array{Float64,2}: first derivatives of PerturbationSolution.Fsys() with respect to arguments X [B]   and XPrime [A]\nState2Control::Array{Float64,2}: observation equation\nLOMstate::Array{Float64,2}: state transition equation\n\n\n\n\n\n","category":"function"},{"location":"PerturbationSolution.html#BASEforHANK.PerturbationSolution.LinearSolution","page":"Perturbation solution","title":"BASEforHANK.PerturbationSolution.LinearSolution","text":"LinearSolution(sr, m_par, A, B; estim)\n\nCalculate the linearized solution to the non-linear difference equations defined by function Fsys(), using Schmitt-Grohé & Uribe (JEDC 2004) style linearization (apply the implicit function theorem to obtain linear observation and state transition equations).\n\nThe Jacobian is calculated using the package ForwardDiff\n\nArguments\n\nsr: steady-state structure (variable values, indexes, numerical parameters, ...)\nA,B: derivative of Fsys() with respect to arguments X [B] and   XPrime [A]\nm_par: model parameters\n\nReturns\n\ngx,hx: observation equations [gx] and state transition equations [hx]\nalarm_LinearSolution,nk: alarm_LinearSolution=true when solving algorithm fails, nk number of   predetermined variables\nA,B: first derivatives of Fsys() with respect to arguments X [B] and   XPrime [A]\n\n\n\n\n\n","category":"function"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"The function linearize_full_model() calls LinearSolution and stores the results in a LinearResults struct.","category":"page"},{"location":"PerturbationSolution.html#LinearSolution()","page":"Perturbation solution","title":"LinearSolution()","text":"","category":"section"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"The LinearSolution function executes the following steps:","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"generate devices to retrieve distribution and marginal value functions from   compressed states/controls (Γ and DC,IDC)\ncalculate the first derivative of BASEforHANK.PerturbationSolution.Fsys() with respect to X and XPrime.   We use automatic differentiation (implemented in Julia by the package ForwardDiff).   Partial derivatives are calculated using the ForwardDiff.jacobian() function.   We exploit that some partial derivatives have known values (contemporaneous marginal value   functions and the future marginal distributions) and set them directly instead of calculating them [BL].\ncompute linear observation and state transition equations using the BASEforHANK.PerturbationSolution.SolveDiffEq() function","category":"page"},{"location":"PerturbationSolution.html#SolveDiffEq()","page":"Perturbation solution","title":"SolveDiffEq()","text":"","category":"section"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"BASEforHANK.PerturbationSolution.SolveDiffEq","category":"page"},{"location":"PerturbationSolution.html#BASEforHANK.PerturbationSolution.SolveDiffEq","page":"Perturbation solution","title":"BASEforHANK.PerturbationSolution.SolveDiffEq","text":"SolveDiffEq(A, B, n_par; estim)\n\nCalculate the solution to the linearized difference equations defined as P'BP xt = P'AP x{t+1}, where P is the (ntotal x r) semi-unitary model reduction matrix n_par.PRightAll of potentially reduced rank r.\n\nArguments\n\nA,B: matrices with first derivatives \nn_par::NumericalParameters: n_par.sol_algo determines   the solution algorithm, options are: \nlitx:  Linear time iteration (implementation follows Reiter)\nschur: Klein's algorithm (preferable if number of controls is small)\n\nReturns\n\ngx,hx: observation equations [gx] and state transition equations [hx]\nalarm_LinearSolution,nk: alarm_LinearSolution=true when solving algorithm fails, nk number of   predetermined variables\n\n\n\n\n\n","category":"function"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"apply the model reduction by pre- and post-multiplying the reduction matrix mathcalP to the Jacobians A and B that are inputs to BASEforHANK.PerturbationSolution.SolveDiffEq(). mathcalP is calculated in model_reduction() and stored in n_par.PRightAll.\ncompute linear observation and state transition equations. The solution algorithm is set   in n_par.sol_algo, with the options :schur (mentioned above) and :litx [lit]. The results are matrices that map contemporaneous states to controls [gx],   or contemporaneous states to future states [hx]","category":"page"},{"location":"PerturbationSolution.html#Fsys()","page":"Perturbation solution","title":"Fsys()","text":"","category":"section"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"BASEforHANK.PerturbationSolution.Fsys","category":"page"},{"location":"PerturbationSolution.html#BASEforHANK.PerturbationSolution.Fsys","page":"Perturbation solution","title":"BASEforHANK.PerturbationSolution.Fsys","text":"Fsys(X, XPrime, XSS, m_par, n_par, indexes, Γ, compressionIndexes, DC, IDC, DCD, IDCD)\n\nEquilibrium error function: returns deviations from equilibrium around steady state.\n\nSplit computation into Aggregate Part, handled by Fsys_agg(), and Heterogeneous Agent Part.\n\nArguments\n\nX,XPrime: deviations from steady state in periods t [X] and t+1 [XPrime]\nXSS: states and controls in steady state\nΓ, DC, IDC, DCD,IDCD: transformation matrices to retrieve marginal distributions [Γ],   marginal value functions [DC,IDC], and the (linear) interpolant of the copula [DCD,IDCD] from deviations\nindexes,compressionIndexes: access XSS by variable names   (DCT coefficients of compressed V_m and V_k in case of compressionIndexes)\n\nExample\n\njulia> # Solve for steady state, construct Γ,DC,IDC as in LinearSolution()\njulia> Fsys(zeros(ntotal),zeros(ntotal),XSS,m_par,n_par,indexes,Γ,compressionIndexes,DC,IDC)\n*ntotal*-element Array{Float64,1}:\n 0.0\n 0.0\n ...\n 0.0\n\n\n\n\n\n","category":"function"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"The function BASEforHANK.PerturbationSolution.Fsys() proceeds in the following way:","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"set up vector F, that contains the errors to all equilibrium conditions. There are as many conditions  as deviations from steady state (length of X,XPrime), and conditions are indexed with  respective model variable in IndexStruct indexes\ngenerate locally all aggregate variables (for both periods) using BASEforHANK.Parsing.@generate_equations\nconstruct the full-grid marginal distributions, marginal value functions, and the copula  from the steady-state values and the (compressed) deviations (for the copula, the selection of DCT  coefficients that can be perturbed ensures that also the perturbed function is a copula)\nwrite all equilibrium condition-errors with respect to aggregate variables to F, using  BASEforHANK.PerturbationSolution.Fsys_agg()\ncompute optimal policies with BASEforHANK.SteadyState.EGM_policyupdate(), given  future marginal value functions, prices, and individual incomes. Infer present marginal  value functions from them (envelope theorem) and set the difference to assumed present  marginal value functions (in terms of their compressed deviation from steady state)  as equilibrium condition-errors (backward iteration of the value function)\ncompute future marginal distributions and the copula (on the copula grid) from previous distribution and optimal asset policies. Interpolate when necessary. Set difference to assumed future marginal distributions and copula values on the copula nodes as equilibrium condition-errors (forward iteration of the distribution)\ncompute distribution summary statistics with BASEforHANK.Tools.distrSummaries() and write  equilibrium conditions with their respective (control) variables\nreturn F","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"Note that the copula is treated as the sum of two interpolants. An interpolant based on the steady-state distribution using the full steady-state marginals as a grid and a \"deviations\"-function that is defined on the copula grid generated in prepare_linearization(). The actual interpolation is carried out with BASEforHANK.Tools.myinterpolate3(). Default setting is trilinear interpolation, the code also allows for 3d-Akima interpolation.","category":"page"},{"location":"PerturbationSolution.html#model_reduction()","page":"Perturbation solution","title":"model_reduction()","text":"","category":"section"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"model_reduction","category":"page"},{"location":"PerturbationSolution.html#BASEforHANK.PerturbationSolution.model_reduction","page":"Perturbation solution","title":"BASEforHANK.PerturbationSolution.model_reduction","text":"model_reduction()\n\nProduce Model Reduction based on Variance Covariance Matrix of States and Controls.\n\nReturns/ Updates\n\nstruct SteadyResults, containing returns of find_steadystate()\n\n\n\n\n\n","category":"function"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"The function model_reduction() derives the approximate factor representation from a first solution of the heterogeneous agent model.[BBL] It then stores the matrices that allow to map the factors to the full set of state and control variables. For deriving the factor representation, the function calculates the long run variance-covariance matrix of all states of the model (given its first-stage reduction).","category":"page"},{"location":"PerturbationSolution.html#update_model()","page":"Perturbation solution","title":"update_model()","text":"","category":"section"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"update_model\nBASEforHANK.PerturbationSolution.Fsys_agg","category":"page"},{"location":"PerturbationSolution.html#BASEforHANK.PerturbationSolution.update_model","page":"Perturbation solution","title":"BASEforHANK.PerturbationSolution.update_model","text":"update_model()\n\nUpdates the linearized model (around the steady state, after parameter changes in the aggregate model) and solves, using LinearSolution_estim(). WARNING: The function is not threadsafe in the sense that calling it will alter the input(!) lr.A/B across threads, if lr is not local to the thread.\n\nReturns\n\nstruct LinearResults, containing\n\nA::Array{Float64,2},B::Array{Float64,2}: first derivatives of Fsys() with respect to arguments X [B]   and XPrime [A]\nState2Control::Array{Float64,2}: observation equation\nLOMstate::Array{Float64,2}: state transition equation\n\n\n\n\n\n","category":"function"},{"location":"PerturbationSolution.html#BASEforHANK.PerturbationSolution.Fsys_agg","page":"Perturbation solution","title":"BASEforHANK.PerturbationSolution.Fsys_agg","text":"Fsys_agg(X, XPrime, XSS, distrSS, m_par, n_par, indexes)\n\nReturn deviations from aggregate equilibrium conditions.\n\nindexes can be both IndexStruct or IndexStructAggr; in the latter case (which is how function is called by LinearSolution_estim()), variable-vectors X,XPrime, and XSS only contain the aggregate variables of the model.\n\n\n\n\n\n","category":"function"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"The function update_model() solves the aggregate model without updating the derivatives of the household/idiosyncratic part. For this purpose the derivatives of BASEforHANK.PerturbationSolution.Fsys_agg() are calculated instead of Fsys(). This substantially speeds up the solution after a parameter change that only affects aggregates.[BBL] In particular, if the model is reduced to its approximate factor representation (see above), this generates significant speed gains.","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"[Klein]: See the paper Using the generalized Schur form to solve a multivariate linear rational expectations model by Paul Klein (JEDC 2000)","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"[BL]: Contemporaneous marginal value functions are irrelevant for optimal decisions, so its effect on other model variables is 0. Due to a rich enough set of prices, the future distribution directly only affects the Fokker-Planck equation. For details, see the paper Solving heterogeneous agent models in discrete time with many idiosyncratic states by perturbation methods, Quantitative Economics, Vol.11(4), November 2020, p. 1253-1288.","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"[BBL]: For details, see the paper Shocks, Frictions, and Inequality in US Business Cycles, American Economic Review, forthcoming.","category":"page"},{"location":"PerturbationSolution.html","page":"Perturbation solution","title":"Perturbation solution","text":"[lit]: Invoking the Implicit Function Theorem, there exist functions g and h such that Fleft(beginpmatrix k  g(k) endpmatrixbeginpmatrix h(k)  g(h(k)) endpmatrixright)=0. Totally differentiating by k yields B beginpmatrixmathbbI Dg endpmatrix+A beginpmatrixmathbbI Dg endpmatrix Dh = 0. The :lit-algorithm solves this equation for Dg and Dh iteratively.","category":"page"},{"location":"Tools.html#Tools","page":"Tools","title":"Tools","text":"","category":"section"},{"location":"Tools.html","page":"Tools","title":"Tools","text":"The Tools submodule provides a set of numerical subroutines such as linear and non-linear interpolation, the Tauchen algorithm to discretize a Gaussian AR-1 process, root-finders and optimizers, wrappers for the schur decomposition, etc.  ","category":"page"},{"location":"Tools.html#Some-of-the-functions-in-detail","page":"Tools","title":"Some of the functions in detail","text":"","category":"section"},{"location":"Tools.html","page":"Tools","title":"Tools","text":"BASEforHANK.Tools.Tauchen\nBASEforHANK.Tools.distrSummaries\nBASEforHANK.Tools.myinterpolate3","category":"page"},{"location":"Tools.html#BASEforHANK.Tools.Tauchen","page":"Tools","title":"BASEforHANK.Tools.Tauchen","text":"Tauchen(rho,N,sigma,mue)\n\nGenerate a discrete approximation to an AR(1) process, following Tauchen (1987).\n\nUses importance sampling: each bin has probability 1/N to realize\n\nArguments\n\nrho: autocorrelation coefficient\nN: number of gridpoints\nsigma: long-run variance\nmue: mean of the AR(1) process\n\nReturns\n\ngrid_vec: state vector grid\nP: transition matrix\nbounds: bin bounds\n\n\n\n\n\n","category":"function"},{"location":"Tools.html#BASEforHANK.Tools.distrSummaries","page":"Tools","title":"BASEforHANK.Tools.distrSummaries","text":"distrSummaries(distr,c_a_star,c_n_star,n_par,inc,incgross,m_par)\n\nCompute distributional summary statistics, e.g. Gini indexes, top-10% income and wealth shares, and 10%, 50%, and 90%-consumption quantiles.\n\nArguments\n\ndistr: joint distribution over bonds, capital and income (m times k times y)\nc_a_star,c_n_star: optimal consumption policies with [a] or without [n]   capital adjustment\nn_par::NumericalParameters, m_par::ModelParameters\ninc: vector of (on grid-)incomes, consisting of labor income (scaled by fracgamma-tau^P1+gamma, plus labor union-profits),   rental income, liquid asset income, capital liquidation income,   labor income (scaled by frac1-tau^P1+gamma, without labor union-profits),   and labor income (without scaling or labor union-profits)\nincgross: vector of (on grid-) pre-tax incomes, consisting of   labor income (without scaling, plus labor union-profits), rental income,   liquid asset income, capital liquidation income,   labor income (without scaling or labor union-profits)\n\n\n\n\n\n","category":"function"},{"location":"Tools.html#BASEforHANK.Tools.myinterpolate3","page":"Tools","title":"BASEforHANK.Tools.myinterpolate3","text":"myinterpolate3(xgrd1, xgrd2, xgrd3, ygrd, xeval1, xeval2, xeval3)\n\nTrilineary project ygrd on (xgrd1,xgrd2,xgrd3) and use it to interpolate value at (xeval1,xeval2,xeval3).\n\nExample\n\njulia> xgrd = [1.0,6.0];\njulia> f((x,y,z)) = x+y+z;\njulia> ygrd = f.(collect(Iterators.product(xgrid,xgrid,xgrid));\njulia> xeval = [3.0,5.0];\njulia> mylinearinterpolate3(xgrd,xgrd,xgrd,ygrd,xeval,xeval,xeval)\n2x2x2 Array{Float64,3}:\n[:,:,1] =\n 9.0 11.0\n11.0 13.0\n[:,:,2] =\n11.0 13.0\n13.0 15.0\n\n\n\n\n\n","category":"function"},{"location":"index.html#BASEforHANK.jl-Documentation","page":"Home","title":"BASEforHANK.jl Documentation","text":"","category":"section"},{"location":"index.html#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"This manual documents the Julia module BASEforHANK, that provides a toolbox for the BAyesian Solution and Estimation (BASE) of a heterogeneous-agent New-Keynesian (HANK) model. It accompanies the paper Shocks, Frictions, and Inequality in US Business Cycles.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"note: Note\nThe toolbox is not a 1-for-1 replication package for the linked paper. In particular, the preset resolution is smaller.","category":"page"},{"location":"index.html#First-steps","page":"Home","title":"First steps","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"The module runs with Julia 1.10.0. We recommend to use Julia for VSCode IDE as a front-end to Julia. To get started with the toolbox, simply download or clone the folder, e.g. via git clone, cd to the project directory and call","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"(v1.10) pkg> activate .\n\n(BASEtoolbox) pkg> instantiate","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"This will install all needed packages. For more on Julia environments, see Pkg.jl.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"warning: Warning\nBefore you activate the environment, make sure that you are in the main directory, in which the Manifest.toml and Project.toml files are located. In case you accidentally activated the environment in a subfolder, empty .toml files will be created that you need to delete before proceeding in the correct folder.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"For an introduction, it is easiest to use the Julia script script.jl in the src folder. Make sure that the folder is the present working directory and that the bottom bar in VSCode shows Julia env: BASEtoolbox.[1] At the top of the script file, we pre-process some user input regarding the aggregate model and the steady state (see below) and write them them into the respective functions in the folder Preprocessor\\generated_fcns. This has to be done before the BASEforHANK module, defined in BASEforHANK.jl, is loaded via","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"include(\"BASEforHANK.jl\")\nusing .BASEforHANK","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"# !!! note\n#\n#    Instead of including the `BASEforHANK` package directly, you can also copy the folder to\n#    the place where packages are stored in the local Julia environment.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"BASEforHANK.jl is the key module file as it loads in the code base, sets up structures, and exports a number of functions and macros.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The provided script.jl then shows how a typical estimation proceeds in three main steps. First, we solve the steady state of the model. Then, the algorithm performs a two-step dimensionality reduction as described in the accompanying paper.[BBL] The second step of this reduction uses the prior information to obtain and approximate factor representation from an initial, not further reduced solution. Secondly, we compute the linearized dynamics of the reduced model around the steady state. Thirdly, we construct the likelihood of the model parameters given the data and use Bayesian methods to estimate them. More details on the three steps are provided in the menu on the left. script.jl also provides an example on how to plot some impulse response functions from the model.","category":"page"},{"location":"index.html#Setting-up-your-model","page":"Home","title":"Setting up your model","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"To define the aggregate part of the model, include the aggregate model block in Model\\input_aggregate_model.jl. The model variables are divided into states (distribution, productivity, ...) and controls (consumption policy or marginal utilities/value functions, prices, aggregate capital stock, ...). The aggregate variables (i.e. excluding the distribution and marginal utilities/value functions) are defined  in Model\\include_aggregate_names and their steady states in Model\\input_aggregate_steady_state. Include model parameters in struct ModelParameters in Model\\Parameters.jl.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The file Parameters.jl contains three structures to provide model parameters, numerical parameters, and estimation settings. In addition, it contains two macros that automatically create structures that contain the model variables.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The model parameters for the steady state have to be calibrated. We set them in the struct ModelParameters. It also contains all other parameters that are estimated, including the stochastic process-parameters for the aggregate shocks. Each model parameter has a line of code. It starts with the parameter name as it is used in the code and a default value. The next two entries are its ascii name and its name for LaTeX output. The fourth entry is the prior if the parameter is to be estimated. Please see the Distributions.jl-package for available options. The fifth entry is a Boolean whether the parameter should be estimated (true) or not (false).","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The folder Model also contains the mapping of prices to household incomes (given the idiosyncratic state space). This can be found in the subfolder IncomesETC. Depending on the adjustments to the macroeconomic model, the user needs to adjust this mapping from prices to incomes. Similarly, the subfolder contains definitions of utility functions, profit functions, employment demand, etc. that are used in the calculation of the steady state equilibrium.","category":"page"},{"location":"index.html#Steady-state-and-first-dimensionality-reduction","page":"Home","title":"Steady state and first dimensionality reduction","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"The command","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"sr_full = compute_steadystate(m_par)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"calls the functions BASEforHANK.find_steadystate() and BASEforHANK.prepare_linearization() and saves their returns in an instance sr_full of the struct SteadyResults. sr_full contains vectors of the steady-state variables (together with index-vectors to reference them by name) and the steady-state distribution of income and assets. It also contains the marginal value functions and the distributions as well as their first-stage model reduction counterparts (obtained through DCTs).","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"tip: Tip\nsr_full may be saved to the local file system by calling@save \"Output/Saves/steadystate.jld2\" sr_fulland can be loaded for a future session with@load \"Output/Saves/steadystate.jld2\" sr_full","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"More details can be found in the section \"Steady State\".","category":"page"},{"location":"index.html#Linearize-full-model","page":"Home","title":"Linearize full model","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"After computing the steady state and saving it in the SteadyResults-struct named sr_full,","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"lr_full = linearize_full_model(sr_full, m_par)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"computes the linear dynamics of the \"full\" model, i.e., using the first-stage model reduction, around the steady state (in the background, this calls BASEforHANK.PerturbationSolution.LinearSolution()) and saves a state-space representation in the instance lr_full of the struct LinearResults (see linearize_full_model()).","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"Linearization of the full model takes a few seconds. The resulting state space is relatively large, because the copula and the value functions are treated fully flexible in this first step. As a result, also computing the first-order dynamics of this model takes a few seconds as well.","category":"page"},{"location":"index.html#Model-reduction","page":"Home","title":"Model reduction","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"This large state-space representation can, however, be reduced substantially using an approximate factor representation. For this purpose, run  ","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"sr_reduc    = model_reduction(sr_full, lr_full, m_par)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"which calculates the unconditional covariance matrix of all state and control variables and rewrites the coefficients of the value functions and the copula as linear combinations of some underlying factors. Only those factors that have eigenvalues above the precision predefined in sr_full.n_par.compress_critC (controls, i.e., marginal value functions) and sr_full.n_par.compress_critS (states, i.e., the copula) are retained.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"warning: Warning\nAfter model reduction, sr_reduc.indexes_r contains the indexes that map correctly into the states/controls used in LOMstate and State2Control.","category":"page"},{"location":"index.html#Model-solution-after-a-parameter-change-/-after-reduction","page":"Home","title":"Model solution after a parameter change / after reduction","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"This smaller model (or any model after a parameter change that doesn't affect the steady state) can be solved quickly using a factorization result from [BBL] running","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"lr_reduc    = update_model(sr_reduc, lr_full, m_par)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"In the background, this calls BASEforHANK.PerturbationSolution.LinearSolution_estim(), which only updates the Jacobian entries that regard the aggregate model. (Note that both BASEforHANK.PerturbationSolution.LinearSolution() and BASEforHANK.PerturbationSolution.LinearSolution_estim() call BASEforHANK.PerturbationSolution.SolveDiffEq() to obtain a solution to the linearized difference equation.)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"This model update step takes about 100ms on a standard computer for the medium size resolution used as a default in the example code.","category":"page"},{"location":"index.html#Estimation-of-model-parameters","page":"Home","title":"Estimation of model parameters","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Having obtained SteadyResults sr_reduc and LinearResults lr_reduc, the command","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"er_mode = find_mode(sr_reduc, lr_reduc, m_par)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"computes the mode of the likelihood, i.e., the parameter vector that maximizes the probability of observing the data given the model, and saves the results in er_mode, an instance of struct EstimResults (see BASEforHANK.Estimation.mode_finding()). We use the Kalman filter to compute the likelihood, and the package Optim for optimization. Settings for the estimation can adjusted in the struct EstimationSettings.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"warning: Warning\nBy default, the flag estimate_model in the struct EstimationSettings is set to false. Depending on the computing power available, finding the mode of the likelihood can take several hours to run through. The mode finder might also seem frozen after finishing the optimization but the computation of the Hessian for the large model is involved and can take a long time for the large model. For instructional purposes, we therefore set e_set.compute_hessian = false by default and load the Hessian from a save file. For a proper estimation, this has to be set to true. We also save an intermediate step before computing the Hessian in case you are only interested in the mode itself.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"Lastly,","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"sample_posterior(sr_reduc, lr_reduc, er_mode, m_par)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"uses a Markov Chain Monte Carlo method to trace out the posterior probabilites of the estimated parameters. The final estimates (and further results) are saved in a file with the name given by the field save_posterior_file in the struct EstimationSettings (instantiated in e_set).","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"note: Note\nThe module BASEforHANK creates the estimation settings e_set in its main script (when it is initialized), so changes to the struct EstimationSettings are only effective before using BASEforHANK. Make sure that all file paths specified in EstimationSettings are correct relative to your script's position.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"[1]: If you use a different editor, make sure that the environment is correctly set, as otherwise the instantiated packages might not be found.","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"[BBL]: For details, see the paper Shocks, Frictions, and Inequality in US Business Cycles, American Economic Review, forthcoming.","category":"page"}]
}
